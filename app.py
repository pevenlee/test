import streamlit as st
import pandas as pd
import json
import warnings
import os
import re
import numpy as np
import base64
import time
# ç¡®ä¿ä½ å·²ç»å®‰è£…äº† google-genai åº“
# pip install google-genai
from google import genai
from google.genai import types

# å¿½ç•¥æ— å…³è­¦å‘Š
warnings.filterwarnings('ignore')

# ================= 1. åŸºç¡€é…ç½® =================

st.set_page_config(
    page_title="ChatBI by Pharmcube", 
    layout="wide", 
)

# --- æ¨¡å‹é…ç½® ---
MODEL_FAST = "gemini-2.0-flash"        
MODEL_SMART = "gemini-3-pro-preview"        

# --- å¸¸é‡å®šä¹‰ ---
JOIN_KEY = "è¯å“ç´¢å¼•"
FILE_FACT = "fact.csv"        
FILE_DIM = "ipmdata.xlsx"
LOGO_FILE = "logo.png"

# [å¤´åƒå®šä¹‰]
USER_AVATAR = "clt.png"  # ç”¨æˆ·å¤´åƒæ–‡ä»¶å
BOT_AVATAR = "pmc.png"   # AIå¤´åƒæ–‡ä»¶å

try:
    FIXED_API_KEY = st.secrets["GENAI_API_KEY"]
except:
    FIXED_API_KEY = "" # è¯·ç¡®ä¿è¿™é‡Œæœ‰ä½ çš„ API Key æˆ–è€…é€šè¿‡ st.secrets é…ç½®

# ================= 2. è§†è§‰ä½“ç³» (Noir UI - ä¾§è¾¹æ å‡çº§ç‰ˆ) =================

def get_base64_image(image_path):
    """è¯»å–æœ¬åœ°å›¾ç‰‡å¹¶è½¬ä¸º Base64"""
    if not os.path.exists(image_path):
        return None
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

def inject_custom_css():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Inter:wght@400;600&display=swap');
        
        :root {
            --bg-color: #050505;
            --border-color: #333333;
            --text-primary: #E0E0E0;
            --accent-error: #FF3333;
            --radius-md: 8px; /* å®šä¹‰é€šç”¨åœ†è§’å˜é‡ */
            --header-height: 60px; /* ç»Ÿä¸€å®šä¹‰é¡¶å¯¼é«˜åº¦ */
        }

        /* å…¨å±€å­—ä½“ */
        .stApp, .element-container, .stMarkdown, .stDataFrame, .stButton, div[data-testid="stDataEditor"] {
            font-family: "Microsoft YaHei", "SimHei", 'JetBrains Mono', monospace !important;
            background-color: var(--bg-color);
        }
        
        /* å…¨å±€åœ†è§’è®¾ç½® */
        div, input, select, textarea { border-radius: var(--radius-md) !important; }
        
        /* æŒ‰é’®æ ·å¼ */
        .stButton button {
            border-radius: var(--radius-md) !important;
            text-align: left !important;
            justify-content: flex-start !important;
            padding-left: 15px !important;
            border: 1px solid #333 !important;
            background: #111 !important;
            color: #CCC !important;
            transition: all 0.2s ease;
        }
        .stButton button:hover {
            border-color: #666 !important;
            color: #FFF !important;
            background: #222 !important;
        }

        /* === å¸ƒå±€æ ¸å¿ƒä¿®æ­£ === */
        
        /* 1. é¡¶éƒ¨å¯¼èˆªæ  (æœ€é«˜å±‚çº§) */
        .fixed-header-container {
            position: fixed; top: 0; left: 0; width: 100%; height: var(--header-height);
            background-color: rgba(5,5,5,0.95);
            border-bottom: 1px solid var(--border-color);
            z-index: 999999 !important; 
            display: flex; align-items: center; justify-content: space-between;
            
            /* --- CHANGE THIS LINE --- */
            /* Old: padding: 0 100px 0 24px; */
            padding: 0 24px; /* Changed right padding from 100px to 24px */
        }

        /* 2. ä¾§è¾¹æ å®¹å™¨ (ä¸‹æ²‰åˆ°é¡¶å¯¼ä¸‹æ–¹) */
        section[data-testid="stSidebar"] {
            top: var(--header-height) !important; /* é¡¶éƒ¨è·ç¦» = é¡¶å¯¼é«˜åº¦ */
            height: calc(100vh - var(--header-height)) !important; /* é«˜åº¦ = å±å¹• - é¡¶å¯¼ */
            z-index: 999998 !important; /* å±‚çº§ç•¥ä½äºé¡¶å¯¼ */
            background-color: #0A0A0A !important; 
            border-right: 1px solid #333;
            padding-top: 20px !important; 
            box-shadow: 2px 0 10px rgba(0,0,0,0.3);
        }
        
        /* 3. å±•å¼€æŒ‰é’® (Collapsed Control) ä½ç½®ä¿®æ­£ */
        [data-testid="stSidebarCollapsedControl"] {
            position: fixed !important;
            top: 75px !important; /* 60px(é¡¶å¯¼) + 15px(é—´è·) */
            left: 20px !important;
            z-index: 1000000 !important; /* æ¯”é¡¶å¯¼è¿˜è¦é«˜ï¼Œç¡®ä¿èƒ½ç‚¹åˆ° */
            background-color: transparent !important;
            color: #E0E0E0 !important;
            display: block !important; 
        }
        
        [data-testid="stSidebarCollapsedControl"] svg {
            fill: #E0E0E0 !important;
            color: #E0E0E0 !important;
        }

        /* 4. Streamlit åŸç”Ÿ Header (é€æ˜åŒ–å¹¶ç½®é¡¶) */
        header[data-testid="stHeader"] { 
            background: transparent !important; 
            z-index: 999999 !important; 
            height: var(--header-height) !important;
        }
        header[data-testid="stHeader"] > div:first-child {
            background: transparent !important;
        }
        
        /* === 5. [æ–°å¢] ä¾§è¾¹æ æ•°æ®å­—å…¸æ ·å¼ (Chips) === */
        .dict-category {
            font-size: 13px;
            font-weight: 700;
            color: #888;
            margin-top: 20px;
            margin-bottom: 8px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .chip-container {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
            margin-bottom: 10px;
        }
        
        .field-chip {
            display: inline-flex;
            align-items: center;
            background-color: #1A1A1A;
            border: 1px solid #333;
            border-radius: 6px; /* åœ†è§’çŸ©é˜µ */
            padding: 4px 8px;
            font-size: 11px;
            color: #CCC;
            font-family: 'JetBrains Mono', monospace;
            transition: all 0.2s;
        }
        .field-chip:hover {
            border-color: #555;
            color: #FFF;
            background-color: #222;
        }
        .field-chip.highlight {
            border-color: #444;
            background-color: #181818;
            color: #4CAF50; /* ç»¿è‰²é«˜äº® */
        }
        
        /* --- å…¶ä»–æ ·å¼ --- */
        
        .nav-left { display: flex; align-items: center; gap: 12px; }
        .nav-logo-img { height: 28px; width: auto; }
        .nav-logo-text { font-weight: 700; font-size: 18px; color: #FFF; letter-spacing: -0.5px; }
        
        .nav-right { display: flex; align-items: center; gap: 12px; }
        .user-avatar-circle {
            width: 36px; height: 36px;
            border-radius: 50%;
            border: 1px solid #444;
            overflow: hidden;
            display: flex; align-items: center; justify-content: center;
            background: #111;
        }
        .user-avatar-circle img { width: 100%; height: 100%; object-fit: cover; }

        .block-container { padding-top: 80px !important; max-width: 1200px; }
        footer { display: none !important; }

        /* === èŠå¤©æ°”æ³¡ & å¤´åƒ === */
        [data-testid="stChatMessage"] { background: transparent !important; border: none !important; padding: 10px 0 !important; }
        
        [data-testid="stChatMessageAvatarBackground"] { 
            background-color: #000000 !important; 
            border: 1px solid #ffffff !important;
            color: #ffffff !important;
            box-shadow: none !important;
            display: flex !important;
        }
        .stChatMessage .stChatMessageAvatarImage {
            width: 100%; height: 100%; object-fit: cover;
            border-radius: 50%;
        }
        
        .msg-prefix { font-weight: bold; margin-right: 8px; font-size: 12px; }
        .p-user { color: #888; }
        .p-ai { color: #00FF00; }

        /* === åº•éƒ¨è¾“å…¥æ¡† === */
        [data-testid="stBottom"] { background: transparent !important; border-top: 1px solid var(--border-color); }
        .stChatInputContainer textarea { 
            background: #050505 !important; color: #fff !important; 
            border: 1px solid #333 !important; 
            border-radius: var(--radius-md) !important;
        }
        
        /* === æ€è€ƒè¿‡ç¨‹ (Thinking Box) === */
        .thought-box {
            font-family: 'JetBrains Mono', "Microsoft YaHei", monospace;
            font-size: 12px; color: #888;
            border-left: 2px solid #444;
            background: #080808;
            padding: 10px;
            margin-bottom: 10px;
            text-align: left !important;
            border-radius: 0 var(--radius-md) var(--radius-md) 0;
        }
        
        /* Streamlit Expander */
        .streamlit-expanderHeader {
            background-color: #0A0A0A !important; color: #888 !important;
            border: 1px solid #222 !important; font-size: 12px !important;
            border-radius: var(--radius-md) !important;
        }
        .streamlit-expanderContent {
            background-color: #050505 !important; border: 1px solid #222 !important;
            border-top: none !important; color: #CCC !important;
            border-radius: 0 0 var(--radius-md) var(--radius-md) !important;
        }

        /* åè®®å¡ç‰‡ */
        .protocol-box { 
            background: #0F0F0F; padding: 12px; border: 1px solid #333; 
            margin-bottom: 15px; font-size: 12px; 
            text-align: left !important;
            border-radius: var(--radius-md); 
        }
        .protocol-row { display: flex; justify-content: flex-start; border-bottom: 1px solid #222; padding: 6px 0; }
        .protocol-row:last-child { border-bottom: none; }
        .protocol-key { color: #666; width: 80px; font-weight: bold; flex-shrink: 0; } 
        .protocol-val { color: #DDD; word-break: break-all; }
        
        /* æ´å¯Ÿæ¡† */
        .insight-box { 
            background: #0A0A0A; padding: 15px; border-left: 3px solid #FFF; color: #DDD; margin-top: 10px; 
            text-align: left !important;
            border-radius: 0 var(--radius-md) var(--radius-md) 0; 
        }
        .mini-insight { color: #DDD; font-size: 12px; font-style: italic; border-top: 1px solid #222; margin-top: 8px; padding-top: 4px; }
        
        /* é”™è¯¯æç¤º */
        .custom-error {
            background-color: rgba(40, 0, 0, 0.9); border: 1px solid var(--accent-error); color: #ffcccc;
            padding: 15px; font-size: 13px; margin-bottom: 1rem; display: flex; align-items: center; gap: 10px;
            border-radius: var(--radius-md);
        }
        </style>
    """, unsafe_allow_html=True)

# ================= 3. æ ¸å¿ƒå·¥å…·å‡½æ•° =================

@st.cache_resource
def get_client():
    if not FIXED_API_KEY: return None
    try: return genai.Client(api_key=FIXED_API_KEY, http_options={'api_version': 'v1beta'})
    except Exception as e: st.error(f"SDK Error: {e}"); return None

@st.cache_data
def load_local_data(filename):
    if not os.path.exists(filename): return None
    df = None
    try:
        if filename.endswith('.xlsx'):
            df = pd.read_excel(filename, engine='openpyxl')
        else:
            try: df = pd.read_csv(filename)
            except: df = pd.read_csv(filename, encoding='gbk')
    except: return None

    if df is not None:
        df.columns = df.columns.str.strip()
        if JOIN_KEY in df.columns:
            df[JOIN_KEY] = df[JOIN_KEY].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
            
        for col in df.columns:
            if df[col].dtype == 'object': df[col] = df[col].astype(str)
            if any(k in str(col) for k in ['é¢', 'é‡', 'Sales', 'Qty']):
                try: df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
                except: pass
            if any(k in str(col).lower() for k in ['æ—¥æœŸ', 'date', 'time', 'year', 'month']):
                try: df[col] = pd.to_datetime(df[col], errors='coerce').fillna(df[col])
                except: pass
        return df
    return None

def get_dataframe_info(df, name="df"):
    if df is None: return f"{name}: NULL"
    info = [f"è¡¨å: `{name}` ({len(df)} è¡Œ)"]
    info.append("| å­—æ®µ | ç±»å‹ | èŒƒå›´/ç¤ºä¾‹ |")
    info.append("|---|---|---|")
    for col in df.columns:
        dtype = str(df[col].dtype)
        if pd.api.types.is_datetime64_any_dtype(df[col]) or "date" in str(col).lower() or "æ—¥æœŸ" in str(col):
            try:
                temp_col = pd.to_datetime(df[col], errors='coerce')
                min_date = temp_col.min()
                max_date = temp_col.max()
                if pd.notnull(min_date) and pd.notnull(max_date):
                    sample = f"{min_date.strftime('%Y-%m-%d')} ~ {max_date.strftime('%Y-%m-%d')}"
                else:
                    sample = list(df[col].dropna().unique()[:3])
            except:
                sample = list(df[col].dropna().unique()[:3])
        else:
            sample = list(df[col].dropna().unique()[:3])
            
        info.append(f"| {col} | {dtype} | {str(sample)} |")
    return "\n".join(info)

def clean_json_string(text):
    try: return json.loads(text)
    except:
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match:
            try: return json.loads(match.group(0))
            except: pass
        match_list = re.search(r'\[.*\]', text, re.DOTALL)
        if match_list:
             try: return json.loads(match_list.group(0))
             except: pass
    return None

# --- [æ–°å¢] API é‡è¯•é€»è¾‘æ ¸å¿ƒ ---
def safe_generate(client, model, prompt, mime_type="text/plain", max_retries=3):
    """
    å¸¦é‡è¯•æœºåˆ¶çš„ API è°ƒç”¨
    """
    config = types.GenerateContentConfig(response_mime_type=mime_type)
    
    retry_count = 0
    base_delay = 2 # åˆå§‹ç­‰å¾… 2 ç§’
    
    while retry_count <= max_retries:
        try:
            return client.models.generate_content(model=model, contents=prompt, config=config)
        except Exception as e:
            error_str = str(e)
            # æ£€æŸ¥æ˜¯å¦ä¸º 429 (Resource exhausted) æˆ– 503 (Server unavailable)
            if "429" in error_str or "429" in str(getattr(e, 'code', '')) or "Resource exhausted" in error_str:
                if retry_count == max_retries:
                    # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
                    return type('obj', (object,), {'text': f"Error (Max Retries): {e}"})
                
                wait_time = base_delay * (2 ** retry_count) # æŒ‡æ•°é€€é¿: 2s, 4s, 8s
                st.toast(f"â³ API è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œæ­£åœ¨é‡è¯• ({retry_count + 1}/{max_retries})...ç­‰å¾… {wait_time}ç§’", icon="âš ï¸")
                time.sleep(wait_time)
                retry_count += 1
            else:
                # å¦‚æœæ˜¯å…¶ä»–é”™è¯¯ (å¦‚ 400 Bad Request)ï¼Œç›´æ¥è¿”å›ï¼Œä¸é‡è¯•
                return type('obj', (object,), {'text': f"Error: {e}"})

def stream_generate(client, model, prompt, max_retries=3):
    """
    å¸¦é‡è¯•æœºåˆ¶çš„æµå¼ç”Ÿæˆ
    æ³¨æ„ï¼šæµå¼ç”Ÿæˆå¦‚æœä¸­é€”ä¸­æ–­ï¼Œé€šå¸¸éœ€è¦é‡æ–°å¼€å§‹æ•´ä¸ªè¯·æ±‚
    """
    config = types.GenerateContentConfig(response_mime_type="text/plain")
    
    retry_count = 0
    base_delay = 2
    
    while retry_count <= max_retries:
        try:
            response = client.models.generate_content_stream(
                model=model, 
                contents=prompt, 
                config=config
            )
            for chunk in response:
                if chunk.text:
                    yield chunk.text
            return # æˆåŠŸç”Ÿæˆå®Œåˆ™é€€å‡ºå‡½æ•°
            
        except Exception as e:
            error_str = str(e)
            if "429" in error_str or "429" in str(getattr(e, 'code', '')) or "Resource exhausted" in error_str:
                if retry_count == max_retries:
                    yield f"Stream Error (Max Retries): {e}"
                    return
                
                wait_time = base_delay * (2 ** retry_count)
                st.toast(f"â³ æµå¼ç”Ÿæˆè¿æ¥ç¹å¿™ï¼Œæ­£åœ¨é‡è¯• ({retry_count + 1}/{max_retries})...", icon="âš ï¸")
                time.sleep(wait_time)
                retry_count += 1
            else:
                yield f"Stream Error: {e}"
                return

def simulated_stream(text, speed=0.01):
    for word in text:
        yield word
        time.sleep(speed)

def format_display_df(df):
    if not isinstance(df, pd.DataFrame): return df
    df_fmt = df.copy()
    for col in df_fmt.columns:
        if pd.api.types.is_numeric_dtype(df_fmt[col]):
            if "year" in str(col).lower() or "å¹´" in str(col):
                df_fmt[col] = df_fmt[col].apply(lambda x: str(int(x)) if pd.notnull(x) else "-")
            else:
                df_fmt[col] = df_fmt[col].apply(lambda x: f"{x:,.2f}".rstrip('0').rstrip('.') if pd.notnull(x) else "-")
        elif pd.api.types.is_datetime64_any_dtype(df_fmt[col]):
            df_fmt[col] = df_fmt[col].dt.strftime('%Y-%m-%d')
    return df_fmt

def normalize_result(res):
    if res is None: return pd.DataFrame()
    if isinstance(res, pd.DataFrame): return res
    if isinstance(res, pd.Series): return res.to_frame(name='æ•°å€¼').reset_index()
    if isinstance(res, dict): return pd.DataFrame(list(res.items()), columns=['Key', 'Value'])
    if isinstance(res, list): return pd.DataFrame(res)
    return pd.DataFrame([str(res)], columns=['ç»“æœ'])

def safe_check_empty(df):
    if df is None: return True
    if not isinstance(df, pd.DataFrame): return True
    return df.empty

def get_history_context(limit=5):
    history_msgs = st.session_state.messages[:-1] 
    relevant_msgs = history_msgs[-(limit * 2):]
    context_str = ""
    if not relevant_msgs: return "æ— å†å²è®°å½•"
    for msg in relevant_msgs:
        role = "ç”¨æˆ·" if msg["role"] == "user" else "AI"
        content = msg["content"]
        if msg["type"] == "df": content = "[å·²å±•ç¤ºæ•°æ®è¡¨]"
        context_str += f"{role}: {content}\n"
    return context_str

def render_protocol_card(summary):
    intent = summary.get('intent', '-')
    scope = summary.get('scope', '-')
    metrics = summary.get('metrics', '-')
    logic = summary.get('logic', '-')
    
    st.markdown(f"""
    <div class="protocol-box">
        <div class="protocol-row"><span class="protocol-key">æ„å›¾è¯†åˆ«</span><span class="protocol-val">{intent}</span></div>
        <div class="protocol-row"><span class="protocol-key">æ•°æ®èŒƒå›´</span><span class="protocol-val">{scope}</span></div>
        <div class="protocol-row"><span class="protocol-key">è®¡ç®—æŒ‡æ ‡</span><span class="protocol-val">{metrics}</span></div>
        <div class="protocol-row"><span class="protocol-key">è®¡ç®—é€»è¾‘</span><span class="protocol-val">{logic}</span></div>
    </div>
    """, unsafe_allow_html=True)

def handle_followup(question):
    st.session_state.messages.append({"role": "user", "type": "text", "content": question})

def safe_exec_code(code_str, context):
    context.update({"pd": pd, "np": np, "st": st})
    context['result'] = None
    pre_vars = set(context.keys())
    try:
        exec(code_str, context)
        if context.get('result') is not None: return context['result']
        new_vars = set(context.keys()) - pre_vars
        candidates = []
        for var in new_vars:
            if var not in ["pd", "np", "st", "__builtins__", "result"]:
                val = context[var]
                if isinstance(val, (pd.DataFrame, pd.Series)): candidates.append(val)
        if candidates: return candidates[-1]
        return None
    except Exception as e: raise e

def get_avatar(role):
    if role == "user":
        return USER_AVATAR if os.path.exists(USER_AVATAR) else None
    else:
        return BOT_AVATAR if os.path.exists(BOT_AVATAR) else None

# ================= 4. é¡µé¢æ¸²æŸ“ =================

inject_custom_css()
client = get_client()

df_sales = load_local_data(FILE_FACT)
df_product = load_local_data(FILE_DIM)

# --- [é‡æ„] Sidebar: æ•°æ®å­—å…¸ & èŒƒå›´ ---
with st.sidebar:
    st.markdown("### â˜· å¯ç”¨æ•°æ®å­—æ®µèŒƒå›´")
    
    # è·å–æ‰€æœ‰å¯ç”¨åˆ—å
    all_cols = set()
    if df_sales is not None: all_cols.update(df_sales.columns)
    if df_product is not None: all_cols.update(df_product.columns)
    
    def render_chips(label, items, is_highlight=False):
        """æ¸²æŸ“åˆ†ç±»å’Œåœ†è§’çŸ©é˜µæ ‡ç­¾"""
        st.markdown(f"<div class='dict-category'>{label}</div>", unsafe_allow_html=True)
        html = "<div class='chip-container'>"
        has_item = False
        for item in items:
            # ç®€å•å»é‡å’Œæ¸…ç†
            if item in all_cols or label in ["âš™ï¸ æ¸ é“èŒƒå›´", "â±ï¸ æ•°æ®æ—¶é—´"]: 
                extra_class = "highlight" if is_highlight else ""
                html += f"<div class='field-chip {extra_class}'>{item}</div>"
                has_item = True
        html += "</div>"
        if has_item:
            st.markdown(html, unsafe_allow_html=True)
        else:
            st.markdown(f"<span style='font-size:11px; color:#555;'>æš‚æ— å­—æ®µ</span>", unsafe_allow_html=True)

    # ================= [ä¿®æ”¹] 1. æ—¶é—´èŒƒå›´ (å·²ç§»è‡³æœ€å‰) =================
    time_range_str = "æœªåŠ è½½"
    if df_sales is not None:
        # å°è¯•å¯»æ‰¾æ—¶é—´åˆ—
        time_col = None
        for c in df_sales.columns:
            if "å¹´å­£" in c or "date" in c.lower() or "time" in c.lower():
                time_col = c
                break
        
        if time_col:
            try:
                # å‡è®¾æ˜¯ YearQuarter æ ¼å¼ (e.g. 20211 or 2021Q1)
                min_val = df_sales[time_col].min()
                max_val = df_sales[time_col].max()
                
                def fmt_q(val):
                    s = str(val)
                    if "Q" in s: return s
                    if len(s) == 5: return f"{s[:4]}Q{s[-1]}" # 20211 -> 2021Q1
                    return s
                
                time_range_str = f"{fmt_q(min_val)} ~ {fmt_q(max_val)}"
            except:
                time_range_str = "æ ¼å¼è§£æå¤±è´¥"
    
    render_chips("â±ï¸ æ•°æ®æ—¶é—´", [time_range_str], is_highlight=True)

    # ================= 2. äº§å“ä¿¡æ¯ =================
    product_fields = [
        "é€šç”¨å", "å•†å“å", "è¯å“åç§°", "æˆåˆ†å", "ç”Ÿäº§ä¼ä¸š", "é›†å›¢åç§°", 
        "è§„æ ¼", "å‰‚å‹", "ATC1Des", "ATC2Des", "ATC3Des", "ATC4Des",
        "è¯å“åˆ†ç±»", "è¯å“åˆ†ç±»äºŒ", "OTC", "é›¶å”®åˆ†ç±»1 æè¿°", "é›¶å”®åˆ†ç±»2 æè¿°", "é›¶å”®åˆ†ç±»3 æè¿°",
        "ç ”ç©¶ç±»å‹", "ä¼ä¸šç±»å‹"
    ]
    render_chips("ğŸ›’ äº§å“ä¿¡æ¯", product_fields)

    # ================= 3. æ”¿ç­–æ ‡ç­¾ =================
    policy_fields = ["åŒ»ä¿", "æœ€æ—©åŒ»ä¿çº³å…¥å¹´ä»½", "é›†é‡‡æ‰¹æ¬¡", "é›†é‡‡ç»“æœ", "ä¸€è‡´æ€§è¯„ä»·", "é¦–æ¬¡ä¸Šå¸‚å¹´ä»£"]
    render_chips("â—† æ”¿ç­–æ ‡ç­¾", policy_fields)

    # ================= 4. æŒ‡æ ‡ç±»å‹ =================
    metric_fields = ["é”€å”®é¢", "é”€å”®é‡"]
    render_chips("ã€½ï¸ æŒ‡æ ‡ç±»å‹", metric_fields)

    # ================= 5. æ¸ é“ =================
    # å°è¯•ä»æ•°æ®ä¸­è·å–æ¸ é“å€¼ï¼Œå¦‚æœä¸è¡Œåˆ™æ˜¾ç¤ºå­—æ®µå
    channel_items = []
    if df_sales is not None and "æ¸ é“" in df_sales.columns:
        try:
            unique_channels = df_sales["æ¸ é“"].dropna().unique().tolist()
            if len(unique_channels) < 10: # å¦‚æœæ¸ é“æ•°é‡å°‘ï¼Œæ˜¾ç¤ºå…·ä½“å€¼
                channel_items = unique_channels
            else:
                channel_items = ["æ¸ é“"]
        except:
            channel_items = ["æ¸ é“"]
    else:
        channel_items = ["æ¸ é“"]
    
    render_chips("âš™ï¸ æ¸ é“èŒƒå›´", channel_items)


    st.markdown("---")
    st.markdown(f"<div style='font-size:10px; color:#666; text-align:center;'>Powered by {MODEL_SMART}</div>", unsafe_allow_html=True)
    
# --- Top Nav ---
logo_b64 = get_base64_image(LOGO_FILE)
if logo_b64:
    logo_html = f'<img src="data:image/png;base64,{logo_b64}" class="nav-logo-img">'
else:
    logo_html = """<svg width="24" height="24" viewBox="0 0 24 24" fill="white"><path d="M12 2L2 22h20L12 2zm0 3.5L19 20H5l7-14.5z"/></svg>"""

user_avatar_b64 = get_base64_image(USER_AVATAR)
if user_avatar_b64:
    user_avatar_html = f'<div class="user-avatar-circle"><img src="data:image/png;base64,{user_avatar_b64}"></div>'
else:
    user_avatar_html = '<div class="user-avatar-circle" style="color:#FFF; font-size:10px;">User</div>'

# è°ƒæ•´åçš„ HTML ç»“æ„
st.markdown(f"""
<div class="fixed-header-container">
    <div class="nav-left">
        {logo_html}
        <div class="nav-logo-text">ChatBI</div>
    </div>
    <div class="nav-right">
        <div class="nav-tag">Peiwen</div>
        {user_avatar_html}
    </div>
</div>
""", unsafe_allow_html=True)

if "messages" not in st.session_state: st.session_state.messages = []

# --- Chat History ---
for msg in st.session_state.messages:
    avatar_file = get_avatar(msg["role"])
    with st.chat_message(msg["role"], avatar=avatar_file):
        if msg["type"] == "text": 
            role_class = "p-ai" if msg["role"] == "assistant" else "p-user"
            prefix = "Doc. > " if msg["role"] == "assistant" else "You > "
            st.markdown(f"<span class='msg-prefix {role_class}'>{prefix}</span>{msg['content']}", unsafe_allow_html=True)
        elif msg["type"] == "df": 
            st.dataframe(msg["content"], use_container_width=True)
        elif msg["type"] == "error":
            st.markdown(f'<div class="custom-error">{msg["content"]}</div>', unsafe_allow_html=True)

# --- çŒœä½ æƒ³é—® (å·¦å¯¹é½æŒ‰é’®) ---
if not st.session_state.messages:
    st.markdown("### æˆ‘ä»¬æ­£åœ¨é€šè¿‡äººå·¥æ™ºèƒ½é‡å¡‘åŒ»è¯æ•°æ®ï¼Œç‚¹äº®åŒ»è¯è¡Œä¸šï¼Œæœ‰ä»€ä¹ˆè¦é—®æˆ‘ä»¬ï¼Ÿ")
    st.markdown("###  ")
    c1, c2, c3 = st.columns(3)
    def handle_preset(question):
        st.session_state.messages.append({"role": "user", "type": "text", "content": question})
        st.rerun()
    if c1.button("â˜‘ï¸ ç¬¬åä¸€æ‰¹é›†é‡‡å¯¹ä¸­å›½åŒ»è¯å¸‚åœºé™¢å†…å¤–äº§ç”Ÿäº†ä»€ä¹ˆæ ·çš„å½±å“ï¼Ÿ"): handle_preset("ç¬¬åä¸€æ‰¹é›†é‡‡å¯¹ä¸­å›½åŒ»è¯å¸‚åœºé™¢å†…å¤–äº§ç”Ÿäº†ä»€ä¹ˆæ ·çš„å½±å“ï¼Ÿ")
    if c2.button("â˜‘ï¸ Kè¯ã€Oè¯ã€æ‹“ç›Šã€è‰¾ç‘å¡ã€è¾¾ä¼¯èˆ’ã€ç™¾æ³½å®‰æœ€è¿‘2å¹´çš„é”€å”®é¢ã€ä»½é¢ã€ä»½é¢å˜åŒ–"): handle_preset("Kè¯ã€Oè¯ã€æ‹“ç›Šã€è‰¾ç‘å¡ã€è¾¾ä¼¯èˆ’ã€ç™¾æ³½å®‰æœ€è¿‘2å¹´çš„é”€å”®é¢ã€ä»½é¢ã€ä»½é¢å˜åŒ–")
    if c3.button("â˜‘ï¸ é”€å”®é¢è¿‡äº¿çš„ï¼Œç‹¬å®¶å¤„æ–¹è¯æœ‰å“ªäº›ï¼Œæ€»ç»“ä¸€ä¸‹ä»–ä»¬çš„ç”»åƒ"): handle_preset("é”€å”®é¢è¿‡äº¿çš„ï¼Œç‹¬å®¶å¤„æ–¹è¯æœ‰å“ªäº›ï¼Œæ€»ç»“ä¸€ä¸‹ä»–ä»¬çš„ç”»åƒ")

# --- Input ---
query = st.chat_input("äº†è§£ä¸­å›½åŒ»è¯å¸‚åœºï¼Œä»è¿™é‡Œå¼€å§‹...")
if query:
    st.session_state.messages.append({"role": "user", "type": "text", "content": query})
    st.rerun()

# --- Core Logic ---
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    
    try:
        user_query = st.session_state.messages[-1]["content"]
        history_str = get_history_context(limit=5)

        with st.chat_message("assistant", avatar=get_avatar("assistant")):
            if df_sales is None or df_product is None:
                err_text = f"æ•°æ®æºç¼ºå¤±ã€‚è¯·æ£€æŸ¥è·¯å¾„é…ç½®ã€‚ (éœ€è¦æ–‡ä»¶: {FILE_FACT}, {FILE_DIM})"
                st.markdown(f'<div class="custom-error">{err_text}</div>', unsafe_allow_html=True)
                st.session_state.messages.append({"role": "assistant", "type": "error", "content": err_text})
                st.stop()

            context_info = f"""
            {get_dataframe_info(df_sales, "df_sales")}
            {get_dataframe_info(df_product, "df_product")}
            KEY: `{JOIN_KEY}`
            """

            # ================= 1. æ„å›¾è¯†åˆ« =================
            intent = "inquiry"
            
            with st.status("æ­£åœ¨åˆ†ææ„å›¾...", expanded=False) as status:
                # [ä¸­æ–‡æç¤ºè¯] æ„å›¾è·¯ç”±
                prompt_router = f"""
                è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡åˆ¤æ–­ç”¨æˆ·çš„æ„å›¾ã€‚
                
                å†å²è®°å½•: {history_str}
                å½“å‰æé—®: "{user_query}"
                
                è§„åˆ™:
                1. è¯¢é—®å…·ä½“æ•°å€¼/æ•°æ®/æŠ¥è¡¨ -> "inquiry"
                2. è¯¢é—®è¶‹åŠ¿/åŸå› /ç»†åˆ†å¸‚åœºåˆ†æ -> "analysis"
                3. ä¸åŒ»è¯æ•°æ®æ— å…³ -> "irrelevant"
                
                ä¸¥æ ¼è¾“å‡º JSON: {{ "type": "result_value" }} (å¿…é¡»æ˜¯ "inquiry", "analysis", "irrelevant" ä¹‹ä¸€)
                """
                resp = safe_generate(client, MODEL_FAST, prompt_router, "application/json")
                
                if "Error" in resp.text:
                    status.update(label="API è¿æ¥é”™è¯¯", state="error")
                    st.stop()
                
                cleaned_data = clean_json_string(resp.text)
                if cleaned_data:
                    intent = str(cleaned_data.get('type', 'inquiry')).lower().strip()
                status.update(label=f"æ„å›¾: {intent.upper()}", state="complete")

            # ================= é€»è¾‘åˆ†æµ =================
            
            # 2. ç®€å•æŸ¥è¯¢
            if 'analysis' not in intent and 'irrelevant' not in intent:
                with st.spinner("æ­£åœ¨ç”ŸæˆæŸ¥è¯¢ä»£ç ï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦1~2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…â€¦"):
                    # [ä¸­æ–‡æç¤ºè¯] ç®€å•æŸ¥è¯¢ & å››è¦ç´ æå–
                    prompt_code = f"""
                    ä½ æ˜¯ä¸€ä½åŒ»è¯è¡Œä¸šçš„ Python ä¸“å®¶ã€‚
                    
                    ã€å†å²å¯¹è¯ã€‘(ç”¨äºç†è§£æŒ‡ä»£)
                    {history_str}
                    
                    ã€å½“å‰ç”¨æˆ·é—®é¢˜ã€‘
                    "{user_query}"
                    
                    ã€æ•°æ®ä¸Šä¸‹æ–‡ã€‘ {context_info}
                    
                    ã€æŒ‡ä»¤ã€‘ 
                    1. ä¸¥æ ¼æŒ‰ç”¨æˆ·è¦æ±‚æå–å­—æ®µã€‚
                    2. ä½¿ç”¨ `pd.merge` å…³è”ä¸¤è¡¨ (é™¤éç”¨æˆ·åªæŸ¥å•è¡¨)ã€‚
                    3. **é‡è¦**: ç¡®ä¿æ‰€æœ‰ä½¿ç”¨çš„å˜é‡ï¼ˆå¦‚ market_shareï¼‰éƒ½åœ¨ä»£ç ä¸­æ˜ç¡®å®šä¹‰ã€‚ä¸è¦ä½¿ç”¨æœªå®šä¹‰çš„å˜é‡ã€‚
                    4. **ç»å¯¹ç¦æ­¢**å¯¼å…¥ IPython æˆ–ä½¿ç”¨ display() å‡½æ•°ã€‚
                    5. ç¦æ­¢ä½¿ç”¨ df.columns = [...] å¼ºè¡Œæ”¹åï¼Œè¯·ä½¿ç”¨ df.rename()ã€‚
                    6. **é¿å… 'ambiguous' é”™è¯¯**ï¼šå¦‚æœ index name ä¸ column name å†²çªï¼Œè¯·åœ¨ reset_index() å‰å…ˆä½¿ç”¨ `df.index.name = None` æˆ–é‡å‘½åç´¢å¼•ã€‚
                    7. ç»“æœå¿…é¡»èµ‹å€¼ç»™å˜é‡ `result`ã€‚
                    8. **ä»½é¢è®¡ç®—å¼ºåˆ¶è§„åˆ™**: 
                    - è®¡ç®—å¸‚åœºä»½é¢æ—¶ï¼Œç»“æœ**å¿…é¡»ä¹˜ä»¥ 100**ï¼Œè½¬æ¢ä¸ºç™¾åˆ†æ•°æ ¼å¼ (Percentage)ã€‚
                    - ä¾‹å¦‚ï¼šé”€å”®é¢/æ€»é¢ = 0.1234ï¼Œåº”å­˜å‚¨ä¸º 12.34ï¼Œè€Œä¸æ˜¯ 0.1234ã€‚
                    - åˆ—åå¿…é¡»åŒ…å« "(%)" ä»¥æç¤ºç”¨æˆ·ï¼Œä¾‹å¦‚ "2024ä»½é¢(%)"ã€‚
                    9. **æ•°æ®ç±»å‹ä¸ç²¾åº¦**:
                    - ä»½é¢åˆ—ã€å˜åŒ–ç‡åˆ—ï¼šå¿…é¡»å¼ºåˆ¶è½¬æ¢ä¸º `float` ç±»å‹ï¼Œä¿ç•™ 1 ä½å°æ•° (`round(1)`)ã€‚
                    - é”€å”®é¢åˆ—ï¼šå¿…é¡»è½¬æ¢ä¸º `int` ç±»å‹ (æ— å°æ•°)ã€‚
                    - **ä¸¥ç¦**å¯¹ä»½é¢åˆ—ä½¿ç”¨ `astype(int)`ï¼Œå¦åˆ™å°äº 1% çš„ä»½é¢ä¼šå˜æˆ 0
                    10. **å¸‚åœºä»½é¢** å½“æåˆ°è®¡ç®—ä»½é¢æ—¶ï¼Œä¼˜å…ˆå®šä¹‰åˆ†æ¯æ˜¯ç”¨æˆ·æåˆ°çš„æ‰€æœ‰äº§å“æ€» > å¯¹åº”ç»†åˆ†é¢†åŸŸä¸‹æ‰€æœ‰äº§å“æ€» > å…¨äº§å“æ€»å’Œï¼›ç„¶åå†åšè®¡ç®—
                    11. **ä»£ç å®‰å…¨ - ä¸¥ç¦ inplace=True åèµ‹å€¼**: 
                        - é”™è¯¯å†™æ³•: `df = df.rename(..., inplace=True)` (è¿™ä¼šå¯¼è‡´ df å˜æˆ None)
                        - æ­£ç¡®å†™æ³•: `df = df.rename(...)` æˆ– `df.rename(..., inplace=True)` (ä¸èµ‹å€¼)
                    
                    
                    ã€å…³é”®æŒ‡ä»¤ã€‘
                    1. **æ•°æ®èŒƒå›´æ£€æŸ¥**: æŸ¥çœ‹ä¸Šä¸‹æ–‡ä¸­çš„æ—¥æœŸèŒƒå›´ã€‚æœ€æ–°çš„æ—¥æœŸå†³å®šäº†â€œå½“å‰å‘¨æœŸâ€ã€‚
                    2. **åŒå£å¾„å¯¹æ¯” (Like-for-Like)**: å½“åˆ†æè·¨å¹´å¢é•¿æˆ–è¶‹åŠ¿æ—¶ï¼Œ**å¿…é¡»**ç­›é€‰å‰ä¸€å¹´çš„æ•°æ®ä»¥åŒ¹é…å½“å‰å¹´ä»½çš„æœˆä»½/å­£åº¦èŒƒå›´ (YTDé€»è¾‘)ã€‚
                        - ä¾‹å¦‚: å¦‚æœæœ€å¤§æ—¥æœŸæ˜¯ 2025-09-30ï¼Œé‚£ä¹ˆâ€œ2024å¹´æ•°æ®â€ç”¨äºå¯¹æ¯”æ—¶ï¼Œåªèƒ½å– 2024-01-01 åˆ° 2024-09-30ï¼Œè€Œä¸æ˜¯2024å…¨å¹´çš„æ•°æ®ã€‚
                    3. è¿”å›æ—¶é—´èŒƒå›´æ—¶ï¼Œéœ€è¦è¯´æ˜ç”¨çš„åŸå§‹è¡¨ä¸­çš„å“ªä¸ªæ—¶é—´æ®µ å¦‚é—®æœ€è¿‘ä¸¤å¹´çš„åŒæ¯”ï¼Œå¦‚æœä¸ºäº†å¯¹é½æ•°æ®ï¼Œåˆ™è¿”å›æ ¼å¼ä¸º 2024Q1~Q3 & 2025Q1~Q3
                    
                    ã€æ‘˜è¦ç”Ÿæˆè§„åˆ™ (Summary)ã€‘
                    - scope (èŒƒå›´): æ•°æ®çš„ç­›é€‰èŒƒå›´ã€‚
                    - metrics (æŒ‡æ ‡): ç”¨æˆ·æŸ¥è¯¢çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚
                    - key_match (å…³é”®åŒ¹é…): **å¿…é¡»è¯´æ˜**æå–äº†ç”¨æˆ·ä»€ä¹ˆè¯ï¼Œå»åŒ¹é…äº†å“ªä¸ªåˆ—ã€‚ä¾‹å¦‚ï¼š"æå–ç”¨æˆ·è¯ 'Kè¯' -> æ¨¡ç³ŠåŒ¹é… 'å•†å“å' åˆ—"ã€‚
                    - logic (åŠ å·¥é€»è¾‘): ç®€è¿°ç­›é€‰å’Œè®¡ç®—æ­¥éª¤ï¼Œä¸¥ç¦æåŠâ€œè¡¨å…³è”â€ã€â€œMergeâ€ç­‰æŠ€æœ¯æœ¯è¯­ã€‚
                    
                    è¾“å‡º JSON: {{ "summary": {{ "intent": "ç®€å•å–æ•°", "scope": "...", "metrics": "...", "key_match": "...", "logic": "..." }}, "code": "..." }}
                    """
                    resp_code = safe_generate(client, MODEL_SMART, prompt_code, "application/json")
                    plan = clean_json_string(resp_code.text)
                
                if plan:
                    # [æ–°åŠŸèƒ½] æ‰“å°æ•°æ®è°ƒç”¨é€»è¾‘
                    summary_obj = plan.get('summary', {})
                    logic_text = summary_obj.get('logic', 'æš‚æ— é€»è¾‘æè¿°')
                    
                    with st.expander("> æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹ (THOUGHT PROCESS)", expanded=True): 
                        # ä½¿ç”¨ placeholder + simulated_stream å®ç°å¸¦æ ·å¼çš„æ‰“å­—æœºæ•ˆæœ
                        logic_placeholder = st.empty()
                        streamed_text = ""
                        # æ¨¡æ‹Ÿæµå¼è¾“å‡º
                        for chunk in simulated_stream(logic_text):
                            streamed_text += chunk
                            logic_placeholder.markdown(f"""
                            <div class="thought-box">
                                <span class="thought-header">é€»è¾‘æ¨æ¼”:</span>
                                {streamed_text}
                            </div>
                            """, unsafe_allow_html=True)
                        
                        st.markdown("**ç”Ÿæˆä»£ç :**")
                        st.code(plan.get('code'), language='python')

                    # æ¸²æŸ“å››è¦ç´ å¡ç‰‡
                    render_protocol_card(summary_obj)
                    
                    try:
                        # ã€ä¿®æ­£ã€‘ä½¿ç”¨ copy() ç¡®ä¿æ•°æ®éš”ç¦»
                        exec_ctx = {"df_sales": df_sales.copy(), "df_product": df_product.copy()}
                        res_raw = safe_exec_code(plan['code'], exec_ctx)
                        res_df = normalize_result(res_raw)
                        
                        if not safe_check_empty(res_df):
                            formatted_df = format_display_df(res_df)
                            st.dataframe(formatted_df, use_container_width=True)
                            st.session_state.messages.append({"role": "assistant", "type": "df", "content": formatted_df})

                            # ==========================================
                            # [æ–°å¢åŠŸèƒ½ START] 1. Flash å¿«é€Ÿæ€»ç»“è¡¨æ ¼
                            # ==========================================
                            try:
                                prompt_summary = f"è¯·ç”¨ç²¾ç‚¼çš„ä¸­æ–‡ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹æ•°æ®çš„ä¸»è¦å‘ç° (ä¸ä½¿ç”¨Markdownæ ¼å¼):\n{formatted_df.to_string()}"
                                resp_summary = safe_generate(client, MODEL_FAST, prompt_summary)
                                summary_text = resp_summary.text.strip()
                                
                                # æ˜¾ç¤ºå¹¶ä¿å­˜æ€»ç»“
                                st.markdown(f'<div class="mini-insight">>> {summary_text}</div>', unsafe_allow_html=True)
                                st.session_state.messages.append({"role": "assistant", "type": "text", "content": summary_text})
                            except Exception as e:
                                pass # æ€»ç»“å¤±è´¥ä¸å½±å“æ•°æ®å±•ç¤º

                            # ==========================================
                            # [æ–°å¢åŠŸèƒ½ START] 2. Smart æ¨¡å‹ç”Ÿæˆè¿½é—®
                            # ==========================================
                            try:
                                # 1. è·å–æ‰€æœ‰å¯ç”¨å­—æ®µå
                                all_columns = []
                                if df_sales is not None: all_columns.extend(df_sales.columns.tolist())
                                if df_product is not None: all_columns.extend(df_product.columns.tolist())
                                # å»é‡å¹¶è½¬ä¸ºå­—ç¬¦ä¸²
                                cols_str = ", ".join(list(set(all_columns)))

                                # 2. æ„å»ºåŒ…å«å­—æ®µä¿¡æ¯çš„æç¤ºè¯
                                prompt_next = f"""
                                åŸºäºç”Ÿæˆçš„è¡¨æ ¼æ•°æ®å’Œæ´å¯Ÿã€‚
                                
                                ã€æ•°æ®åº“å®Œæ•´å¯ç”¨å­—æ®µåˆ—è¡¨ã€‘:
                                {cols_str}
                                
                                ã€æŒ‡ä»¤ã€‘
                                é’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜ "{user_query}"ï¼Œä»ä¸Šé¢çš„â€œå¯ç”¨å­—æ®µåˆ—è¡¨â€ä¸­å¯»æ‰¾çµæ„Ÿï¼Œ
                                ç»™å‡ºå®¢æˆ·æœ€å¯èƒ½æƒ³æ·±å…¥æŒ–æ˜çš„ 2 ä¸ªé—®é¢˜ï¼ˆä¾‹å¦‚ï¼šæŒ‰[æŸä¸ªå…·ä½“å­—æ®µ]æ‹†åˆ†ã€çœ‹[æŸä¸ªå­—æ®µ]çš„è¶‹åŠ¿ç­‰ï¼‰ã€‚
                                
                                ä¸¥æ ¼è¾“å‡º JSON å­—ç¬¦ä¸²åˆ—è¡¨ã€‚
                                ç¤ºä¾‹æ ¼å¼: ["æŸ¥çœ‹è¯¥äº§å“çš„åˆ†åŒ»é™¢æ’å", "åˆ†æä¸åŒå‰‚å‹çš„ä»½é¢å˜åŒ–"]
                                """
                                resp_next = safe_generate(client, MODEL_SMART, prompt_next, "application/json")
                                next_questions = clean_json_string(resp_next.text)

                                if isinstance(next_questions, list) and len(next_questions) > 0:
                                    st.markdown("### æ˜¯å¦è¿½é—®")
                                    c1, c2 = st.columns(2)
                                    
                                    def get_q_text_safe(q):
                                        if isinstance(q, str): return q
                                        if isinstance(q, dict): return q.get('question', list(q.values())[0])
                                        return str(q)

                                    if len(next_questions) > 0: 
                                        q1_text = get_q_text_safe(next_questions[0])
                                        c1.button(f"> {q1_text}", use_container_width=True, on_click=handle_followup, args=(q1_text,))
                                    if len(next_questions) > 1: 
                                        q2_text = get_q_text_safe(next_questions[1])
                                        c2.button(f"> {q2_text}", use_container_width=True, on_click=handle_followup, args=(q2_text,))
                            except Exception as e:
                                pass # è¿½é—®ç”Ÿæˆå¤±è´¥ä¸æŠ¥é”™
                            
                            # ==========================================
                            # [æ–°å¢åŠŸèƒ½ END]
                            # ==========================================

                        else:
                            st.warning("å°è¯•æ¨¡ç³Šæœç´¢...")
                            fallback_code = f"result = df_product[df_product.astype(str).apply(lambda x: x.str.contains('{user_query[:2]}', case=False, na=False)).any(axis=1)].head(10)"
                            try:
                                res_fallback = safe_exec_code(fallback_code, exec_ctx)
                                if not safe_check_empty(normalize_result(res_fallback)):
                                    st.dataframe(res_fallback)
                                    st.session_state.messages.append({"role": "assistant", "type": "df", "content": res_fallback})
                                else:
                                    st.markdown(f'<div class="custom-error">æœªæ‰¾åˆ°ç›¸å…³æ•°æ®</div>', unsafe_allow_html=True)
                            except: pass
                    except Exception as e:
                        st.markdown(f'<div class="custom-error">ä»£ç æ‰§è¡Œé”™è¯¯: {e}</div>', unsafe_allow_html=True)

            # 3. æ·±åº¦åˆ†æ
            elif 'analysis' in intent:
                
                with st.spinner("æ­£åœ¨è§„åˆ’åˆ†æè·¯å¾„ï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦1~2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…..."):
                    # [ä¸­æ–‡æç¤ºè¯] æ·±åº¦åˆ†æ & å››è¦ç´ æå–
                    prompt_plan = f"""
                    è§’è‰²: èµ„æ·±åŒ»è¯æ•°æ®åˆ†æå¸ˆã€‚
                    å†å²è®°å½•: {history_str}
                    å½“å‰æé—®: "{user_query}"
                    æ•°æ®ä¸Šä¸‹æ–‡: {context_info}
                    
                    å…³é”®æŒ‡ä»¤:
                    1. **æ•°æ®èŒƒå›´æ£€æŸ¥**: æŸ¥çœ‹ä¸Šä¸‹æ–‡ä¸­çš„æ—¥æœŸèŒƒå›´ã€‚æœ€æ–°çš„æ—¥æœŸå†³å®šäº†â€œå½“å‰å‘¨æœŸâ€ã€‚
                    2. **åŒå£å¾„å¯¹æ¯” (Like-for-Like)**: å½“åˆ†æè·¨å¹´å¢é•¿æˆ–è¶‹åŠ¿æ—¶ï¼Œ**å¿…é¡»**ç­›é€‰å‰ä¸€å¹´çš„æ•°æ®ä»¥åŒ¹é…å½“å‰å¹´ä»½çš„æœˆä»½/å­£åº¦èŒƒå›´ (YTDé€»è¾‘)ã€‚
                        - ä¾‹å¦‚: å¦‚æœæœ€å¤§æ—¥æœŸæ˜¯ 2025-09-30ï¼Œé‚£ä¹ˆâ€œ2024å¹´æ•°æ®â€ç”¨äºå¯¹æ¯”æ—¶ï¼Œåªèƒ½å– 2024-01-01 åˆ° 2024-09-30ï¼Œè€Œä¸æ˜¯2024å…¨å¹´çš„æ•°æ®ã€‚
                    3. **ä»£ç å®‰å…¨**: ç»å¯¹ç¦æ­¢ `df = df.func(inplace=True)` è¿™ç§å†™æ³•ï¼Œè¿™ä¼šå¯¼è‡´ DataFrame å˜æˆ NoneType å¼•å‘åˆå¹¶é”™è¯¯ã€‚
                    4. **è¯­è¨€**: æ‰€æœ‰çš„ "title" (æ ‡é¢˜), "desc" (æè¿°), å’Œ "intent_analysis" (åˆ†ææ€è·¯) å¿…é¡»ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**ã€‚
                    5. **å®Œæ•´æ€§**: æä¾› 2-5 ä¸ªä¸åŒçš„åˆ†æç»´åº¦ã€‚
                    6. **å˜é‡å®šä¹‰æ£€æŸ¥ (CRITICAL)**: 
                        - **ä¸¥ç¦å¼•ç”¨æœªå®šä¹‰çš„å˜é‡**ï¼ˆä¾‹å¦‚ä»£ç ä¸­å‡ºç°äº† `df_excl` æˆ– `df_temp` ä½†å‰é¢æ²¡æœ‰å®šä¹‰å®ƒï¼‰ã€‚
                        - å‡¡æ˜¯ä½¿ç”¨çš„å˜é‡ï¼Œå¿…é¡»åœ¨å½“å‰ä»£ç å—ä¸­æ˜¾å¼èµ‹å€¼ã€‚
                    
                    ä¸¥æ ¼è¾“å‡º JSON (ä¸è¦Markdown, ä¸è¦ä»£ç å—): 
                    {{ 
                        "summary": {{ 
                             "intent": "æ·±åº¦å¸‚åœºåˆ†æ", 
                             "scope": "äº§å“: [äº§å“å], æ—¶é—´: [YYYY-MM ~ YYYY-MM]",
                             "metrics": "è¶‹åŠ¿ / ç»“æ„ / å¢é•¿é©±åŠ¨åŠ›...", 
                             "logic": "1. æ€»ä½“è¶‹åŠ¿åˆ†æ; 2. äº§å“ç»“æ„æ‹†è§£; 3. å¢é•¿è´¡çŒ®åº¦è®¡ç®—..." 
                        }},
                        "intent_analysis": "è¿™é‡Œç”¨ä¸­æ–‡è¯¦ç»†æè¿°ä½ çš„åˆ†ææ€è·¯ï¼Œç‰¹åˆ«æ˜¯è¯´æ˜ä½ å¦‚ä½•å¤„ç†äº†æ—¶é—´å‘¨æœŸå¯¹é½ï¼ˆä¾‹å¦‚ï¼š'é‰´äºæ•°æ®æˆªæ­¢è‡³2025Q3ï¼Œæˆ‘å°†æå–2024åŒæœŸæ•°æ®è¿›è¡ŒåŒæ¯”åˆ†æ...'ï¼‰", 
                        "angles": [ 
                            {{ "title": "ä¸­æ–‡æ ‡é¢˜", "desc": "ä¸­æ–‡æè¿°", "code": "Python code storing result in `result` variable..." }} 
                        ] 
                    }}
                    """
                    resp_plan = safe_generate(client, MODEL_SMART, prompt_plan, "application/json")
                    plan_json = clean_json_string(resp_plan.text)
                
                if not plan_json:
                    st.error("åˆ†æè§„åˆ’ç”Ÿæˆå¤±è´¥ï¼Œæ¨¡å‹æœªè¿”å›æœ‰æ•ˆæ ¼å¼ã€‚")
                    st.stop()

                if plan_json:
                    # [æ–°åŠŸèƒ½] æ‰“å°åˆ†ææ€è·¯
                    intro_text = plan_json.get('intent_analysis', 'åˆ†ææ€è·¯ç”Ÿæˆä¸­...')
                    intro = f"**åˆ†ææ€è·¯:**\n{intro_text}"
                    
                    with st.expander("> æŸ¥çœ‹åˆ†ææ€è·¯ (ANALYSIS THOUGHT)", expanded=True): 
                         st.write_stream(simulated_stream(intro))
                    
                    st.session_state.messages.append({"role": "assistant", "type": "text", "content": intro})
                    
                    # æ¸²æŸ“å››è¦ç´ å¡ç‰‡ (å¦‚æœæœ‰çš„è¯)
                    if 'summary' in plan_json:
                        render_protocol_card(plan_json['summary'])

                    angles_data = []
                    
                    for angle in plan_json.get('angles', []):
                        with st.container():
                            st.markdown(f"**> {angle['title']}**")
                            
                            # ã€ä¿®æ­£ã€‘å¾ªç¯å†…éƒ¨åˆ›å»ºç‹¬ç«‹ Contextï¼Œé˜²æ­¢æ±¡æŸ“
                            local_ctx = {
                                "df_sales": df_sales.copy(), 
                                "df_product": df_product.copy(),
                                "pd": pd,
                                "np": np
                            }
                            
                            try:
                                res_raw = safe_exec_code(angle['code'], local_ctx)
                                if isinstance(res_raw, dict) and any(isinstance(v, (pd.DataFrame, pd.Series)) for v in res_raw.values()):
                                    res_df = pd.DataFrame() 
                                    for k, v in res_raw.items():
                                        st.markdown(f"**- {k}**")
                                        sub_df = normalize_result(v)
                                        st.dataframe(format_display_df(sub_df), use_container_width=True)
                                        res_df = sub_df 
                                        st.session_state.messages.append({"role": "assistant", "type": "df", "content": sub_df})
                                else:
                                    res_df = normalize_result(res_raw)
                                    if not safe_check_empty(res_df):
                                        formatted_df = format_display_df(res_df)
                                        st.dataframe(formatted_df, use_container_width=True)
                                        st.session_state.messages.append({"role": "assistant", "type": "df", "content": formatted_df})
                                        
                                        # [ä¸­æ–‡æç¤ºè¯] æ•°æ®è§£è¯»
                                        prompt_mini = f"ç”¨ä¸€å¥è¯è§£è¯»ä»¥ä¸‹æ•°æ® (ä¸­æ–‡): \n{res_df.to_string()}"
                                        resp_mini = safe_generate(client, MODEL_FAST, prompt_mini)
                                        explanation = resp_mini.text
                                        st.markdown(f'<div class="mini-insight">>> {explanation}</div>', unsafe_allow_html=True)
                                        angles_data.append({"title": angle['title'], "explanation": explanation})
                                    else:
                                        st.warning(f"{angle['title']} æš‚æ— æ•°æ®")
                            except Exception as e:
                                st.error(f"åˆ†æé”™è¯¯: {e}")

                    if angles_data:
                        st.markdown("### åˆ†ææ€»ç»“")
                        findings = "\n".join([f"[{a['title']}]: {a['explanation']}" for a in angles_data])
                        # [ä¸­æ–‡æç¤ºè¯] æœ€ç»ˆæ€»ç»“
                        prompt_final = f"""åŸºäºä»¥ä¸‹å‘ç°: {findings}ï¼Œå›ç­”é—®é¢˜: "{user_query}"ã€‚è¯·ä½¿ç”¨ä¸“ä¸šã€å®¢è§‚çš„ä¸­æ–‡å£å»ã€‚"""
                        
                        stream_gen = stream_generate(client, MODEL_SMART, prompt_final)
                        final_response = st.write_stream(stream_gen)
                        st.session_state.messages.append({"role": "assistant", "type": "text", "content": f"### åˆ†ææ€»ç»“\n{final_response}"})

                        # === Follow-up questions ===
                        # [ä¸­æ–‡æç¤ºè¯] è¿½é—®ç”Ÿæˆ
                        
                        # 1. è·å–å­—æ®µä¸Šä¸‹æ–‡
                        all_columns = []
                        if df_sales is not None: all_columns.extend(df_sales.columns.tolist())
                        if df_product is not None: all_columns.extend(df_product.columns.tolist())
                        cols_str = ", ".join(list(set(all_columns)))

                        prompt_next = f"""
                        åŸºäºç”Ÿæˆçš„è¡¨æ ¼å’Œæ´å¯Ÿã€‚
                        
                        ã€æ•°æ®åº“å®Œæ•´å¯ç”¨å­—æ®µåˆ—è¡¨ã€‘:
                        {cols_str}
                        
                        ã€æŒ‡ä»¤ã€‘
                        ç»“åˆâ€œå¯ç”¨å­—æ®µåˆ—è¡¨â€ï¼Œç”Ÿæˆ 2 ä¸ªå…·æœ‰æ·±åº¦çš„åç»­åˆ†æé—®é¢˜ã€‚
                        ä»…è¾“å‡ºä¸€ä¸ª JSON å­—ç¬¦ä¸²åˆ—è¡¨ã€‚
                        ç¤ºä¾‹æ ¼å¼: ["åˆ†æå„çœä»½çš„å¸‚åœºè¡¨ç°å·®å¼‚", "æŸ¥çœ‹Top5ä¼ä¸šçš„ç«äº‰æ ¼å±€"]
                        """
                        resp_next = safe_generate(client, MODEL_SMART, prompt_next, "application/json")
                        next_questions = clean_json_string(resp_next.text)

                        if isinstance(next_questions, list) and len(next_questions) > 0:
                            st.markdown("### æ˜¯å¦è¿½é—®")
                            c1, c2 = st.columns(2)
                            
                            def get_q_text(q):
                                if isinstance(q, str): return q
                                if isinstance(q, dict): return q.get('question_zh', q.get('question', list(q.values())[0]))
                                return str(q)

                            if len(next_questions) > 0: 
                                q1_text = get_q_text(next_questions[0])
                                c1.button(f"> {q1_text}", use_container_width=True, on_click=handle_followup, args=(q1_text,))
                            if len(next_questions) > 1: 
                                q2_text = get_q_text(next_questions[1])
                                c2.button(f"> {q2_text}", use_container_width=True, on_click=handle_followup, args=(q2_text,))
            
            elif 'irrelevant' in intent:
                msg = "è¯¥é—®é¢˜ä¼¼ä¹ä¸åŒ»è¯æ•°æ®æ— å…³ï¼Œæˆ‘æ˜¯ ChatBIï¼Œä¸“æ³¨äºåŒ»è¯å¸‚åœºåˆ†æã€‚"
                def simple_stream():
                    for word in msg:
                        yield word
                        time.sleep(0.02)
                st.write_stream(simple_stream)
                st.session_state.messages.append({"role": "assistant", "type": "text", "content": msg})

    except Exception as e:
        import traceback
        st.markdown(f'<div class="custom-error">ç³»ç»Ÿå¼‚å¸¸: {str(e)}</div>', unsafe_allow_html=True)
